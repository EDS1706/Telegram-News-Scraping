import requests
from bs4 import BeautifulSoup
from datetime import datetime
import time
import json
import os

# ×¨×©×™××ª ××ª×¨×™ ×”×—×“×©×•×ª ×œ×‘×“×™×§×”
NEWS_SITES = {
    "https://www.ynet.co.il": "/home/0,7340,L-8,00.html",
    "https://www.themarker.com": "/",
    "https://www.calcalist.co.il": "/home/0,7340,L-8,00.html",
    "https://www.mako.co.il": "/",
    "https://www.maariv.co.il": "/",
}

# ××™×œ×•×ª ×”××¤×ª×— ×œ××¢×§×‘
KEYWORDS = ["McDonalds", "××§'×“×•× ×œ×“×¡", "××§×“×•× ×œ×“×¡", "××œ×¢×œ", "EL-AL", "××œ-×¢×œ", "×™×©×¨××œ", "×‘×™×™×“×Ÿ"]


# ×•×™×“×•× ×©×§×•×‘×¥ ×”-JSON ×§×™×™×
if not os.path.exists("news_dict.json"):
    with open("news_dict.json", "w") as file:
        json.dump({}, file)

# ×”×’×“×¨×ª Headers ×›×“×™ ×œ×× ×•×¢ ×—×¡×™××•×ª
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
}

def get_news():
    news_dict = {}

    for base_url, path in NEWS_SITES.items():
        url = base_url + path
        print(f"\nğŸ” ×‘×•×“×§ ××ª×¨: {url}")

        try:
            req = requests.get(url)
            req.raise_for_status()
        except requests.RequestException as e:
            print(f"âŒ ×©×’×™××” ×‘×˜×¢×™× ×ª ×”××ª×¨ {url}: {e}")
            continue

        soup = BeautifulSoup(req.text, "lxml")

        articles = soup.find_all("h2")
        print(f"ğŸ“° ××¡×¤×¨ ×›×ª×‘×•×ª ×©× ××¦××• ×‘-{base_url}: {len(articles)}")

        for article in articles:
            title_article = article.text.strip()
            url_article = article.find("a")

            if url_article:
                url_article = url_article.get("href")

                # ×”×©×œ××ª ×§×™×©×•×¨ ×× ×”×•× ×™×—×¡×™
                if url_article and url_article.startswith("/"):
                    url_article = base_url + url_article

                print(f"ğŸ”— ×›×ª×‘×”: {title_article}")
                print(f"ğŸ”— ×§×™×©×•×¨: {url_article}")

                # ×‘×“×™×§×” ×× ×”×›×ª×‘×” ××›×™×œ×” ××™×œ×ª ××¤×ª×—
                if any(keyword.lower() in title_article.lower() for keyword in KEYWORDS):
                    article_id = url_article.split("/")[-1]
                    article_date_timestamp = time.time()

                    if article_id not in news_dict:
                        news_dict[article_id] = {
                            "article_date_timestamp": article_date_timestamp,
                            "title_article": title_article,
                            "url_article": url_article,
                        }

                        print(f"âœ… ×›×ª×‘×” ××ª××™××” × ××¦××”! {title_article}")

    with open("news_dict.json", "w") as file:
        json.dump(news_dict, file, indent=4, ensure_ascii=False)

    print(f"\nğŸ“ ×©××¨× ×• {len(news_dict)} ×›×ª×‘×•×ª ×‘-news_dict.json")

def check_update():
    """×‘×•×“×§ ×× × ×•×¡×¤×• ×—×“×©×•×ª ×—×“×©×•×ª ×©×œ× ×”×™×• ×‘×§×•×‘×¥ JSON"""
    try:
        with open("news_dict.json", "r") as file:
            news_dict = json.load(file)
    except (FileNotFoundError, json.JSONDecodeError):
        news_dict = {}

    fresh_news = get_news()

    return fresh_news

def main():
    fresh_news = check_update()
    print(f"{len(fresh_news)} ×›×ª×‘×•×ª ×—×“×©×•×ª × ×©××¨×•.")

if __name__ == "__main__":
    main()
    print("×”×—×“×©×•×ª × ××¡×¤×• ×‘×”×¦×œ×—×”!")
